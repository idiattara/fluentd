{
  "consumer": {
    "spark.streaming.kafka.poll.records": [500, 200, 300, 800, 400],
    "spark.streaming.kafka.consumer.poll.ms": [500, 1000, 800, 1200, 600],
    "spark.streaming.kafka.maxRatePerPartition": [1000, 500, 800, 1200, 600],
    "spark.streaming.kafka.consumer.cache.maxCapacity": [10000, 5000, 8000, 12000, 6000],
    "spark.streaming.kafka.consumer.cache.initialCapacity": [1000, 500, 800, 1200, 600],
    "spark.streaming.kafka.consumer.cache.loadFactor": [0.75, 0.5, 0.8, 0.6, 0.9]
  },
  "processing": {
    "spark.streaming.batchDuration": [1000, 500, 800, 1200, 600],
    "spark.streaming.receiver.maxRate": [500, 200, 300, 800, 400],
    "spark.streaming.blockInterval": [500, 200, 300, 800, 400],
    "spark.streaming.kafka.producer.compression.type": ["gzip", "snappy", "none", "lz4", "zstd"],
    "triggerProcessingTime": ["5 seconds", "10 seconds", "15 seconds", "20 seconds", "25 seconds"]
  },
  "producer": {
    "spark.streaming.kafka.producer.batchSize": [5000, 10000, 8000, 12000, 6000],
    "spark.streaming.kafka.producer.linger.ms": [50, 100, 80, 120, 60],
    "spark.streaming.kafka.producer.buffer.memory": ["100 MB", "50 MB", "80 MB", "120 MB", "60 MB"],
    "spark.streaming.kafka.producer.maxRequestSize": ["5 MB", "1 MB", "2 MB", "8 MB", "4 MB"],
    "ack": [1, 0, -1, 1, 0]
  }
}
